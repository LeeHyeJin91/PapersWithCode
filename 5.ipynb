{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73bcd18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('font', family='AppleGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "973f0fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7184d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d67ba70",
   "metadata": {},
   "source": [
    "#### 모델구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac91e7dd",
   "metadata": {},
   "source": [
    "* Embedding\n",
    "* PositionalEncoding \n",
    "\n",
    "* Encoder  \n",
    "    * EncoderLayer  \n",
    "        *  MultiHeadAttention\n",
    "        *  FeedForward\n",
    "    \n",
    "* Decoder\n",
    "    * DecoderLayer\n",
    "        * MultiHeadAttention\n",
    "        *  FeedForward \n",
    "    \n",
    "     \n",
    "* Transformer\n",
    "    * Encoder\n",
    "    * Decoder   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ce7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Embedding):\n",
    "\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__(vocab_size, d_model)\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        # self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # input\n",
    "        #       x(batch_size, seq_len)\n",
    "        # output\n",
    "        #       x_embd(batch_size, seq_len, d_model)\n",
    "\n",
    "        x_embd = self.embedding(x)\n",
    "        \n",
    "        return x_embd\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee815b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        self.encoding.requires_grad = False \n",
    "\n",
    "        pos = torch.arange(0, max_len)     # (max_len)\n",
    "        pos = pos.float().unsqueeze(dim=1) # (max_len, 1)\n",
    "\n",
    "        _2i = torch.arange(0, d_model, step=2).float() # [0, 2, 4, ...]\n",
    "        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n",
    "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input\n",
    "        #      x(batch_size, seq_len)\n",
    "        # output\n",
    "        #      x_pe(batch_size, seq_len, d_model)\n",
    "\n",
    "        batch_size, seq_len = x.size()\n",
    "        x_pe = self.encoding[:seq_len, :]\n",
    "\n",
    "        return x_pe \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b683b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.scale = torch.sqrt(torch.tensor(int(d_model//n_head)))\n",
    "\n",
    "        self.WQ = nn.Linear(d_model, d_model)\n",
    "        self.WK = nn.Linear(d_model, d_model)\n",
    "        self.WV = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # input:\n",
    "        #        q (batch_size, seq_len, d_model)\n",
    "        #        k (batch_size, seq_len, d_model)\n",
    "        #        v (batch_size, seq_len, d_model) \n",
    "        # output: \n",
    "        #        x                (batch_size, seq_len, d_model)\n",
    "        #        attention_weight (batch_size, n_head, seq_len, seq_len)\n",
    "        \n",
    "        Q = self.WQ(q) # (batch_size, seq_len, d_model)\n",
    "        K = self.WK(k) # (batch_size, seq_len, d_model)\n",
    "        V = self.WV(v) # (batch_size, seq_len, d_model)\n",
    "\n",
    "        batch_size, seq_len, d_model = Q.size()\n",
    "        d = self.d_model // self.n_head\n",
    "        \n",
    "        Q = Q.reshape(batch_size, -1, n_head, d).permute(0,2,1,3) # (batch_size, n_head, seq_len, d_model//n_head)\n",
    "        K = K.reshape(batch_size, -1, n_head, d).permute(0,2,1,3) # (batch_size, n_head, seq_len, d_model//n_head) \n",
    "        V = V.reshape(batch_size, -1, n_head, d).permute(0,2,1,3) # (batch_size, n_head, seq_len, d_model//n_head) \n",
    "        \n",
    "        # attention 연산\n",
    "        \n",
    "        # 1) 유사도 계산\n",
    "        attention_score = (Q @ K.permute(0, 1, 3, 2)) / self.scale # (batch_size, n_head, seq_len, seq_len)  \n",
    "        \n",
    "        # 2) 가중치 계산\n",
    "        if mask is not None:\n",
    "            attention_score[mask] = -1e10\n",
    "        attention_weight = torch.softmax(attention_score, dim=-1) # (batch_size, n_head, seq_len, seq_len)  \n",
    "\n",
    "        # 3) 가중합 계산 \n",
    "        x = attention_weight @ V                                 # (batch_size, n_head, seq_len, d_model//n_head)\n",
    "        x = x.permute(0,2,1,3).reshape(batch_size, -1, d_model)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        return x, attention_weight\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d9b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_ff, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(d_model, d_ff, bias=True) # (d_model, d_ff)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input\n",
    "        #       x(batch_size, seq_len, d_model)\n",
    "        # output\n",
    "        #       x(batch_size, seq_len, d_model)\n",
    "\n",
    "        x = self.linear1(x)  # (batch_size, seq_len, d_ff)\n",
    "        x = self.relu(x)     # (batch_size, seq_len, d_ff)\n",
    "        x = self.dropout(x)  # (batch_size, seq_len, d_ff)\n",
    "        x = self.linear2(x)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63bdc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_ff, n_head, drop_prob):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(d_model, n_head)\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.feedforward = FeedForward(d_model, d_ff, drop_prob)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "\n",
    "    def forward(self, enc_x, enc_mask):\n",
    "        # input \n",
    "        #       enc_x    (batch_size, enc_seq_len, d_model)\n",
    "        #       enc_mask ()\n",
    "        # output\n",
    "        #       x                (batch_size, enc_seq_len, d_model)\n",
    "        #       attention_weight (batch_size, n_head, enc_seq_len, enc_seq_len)\n",
    "\n",
    "        residual, attention_weight = self.self_attention(q=enc_x, k=enc_x, v=enc_x, mask=enc_mask) \n",
    "        residual = self.dropout(residual)\n",
    "        x = self.ln1(enc_x + residual)\n",
    "\n",
    "        residual = self.feedforward(x)\n",
    "        residual = self.dropout(residual)\n",
    "        x = self.ln2(x + residual)\n",
    "\n",
    "        return x, attention_weight\n",
    "        \n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, d_model, d_ff, n_head, drop_prob, max_len, n_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model, d_ff, n_head, drop_prob) for _ in range(n_layers)])\n",
    "        \n",
    "    def forward(self, enc_x, enc_mask):\n",
    "        # input\n",
    "        #      enc_x(batch_size, seq_len)\n",
    "        #      enc_mask()\n",
    "        # output\n",
    "        #      x                 (batch_size, seq_len, d_model)\n",
    "        #      attention_weights (batch_size, n_head, seq_len, seq_len)\n",
    "        \n",
    "        x_embd = self.embedding(enc_x).to(device)    # (batch_size, seq_len, d_model)\n",
    "        x_pos = self.pos_encoding(enc_x).to(device)  # (batch_size, seq_len, d_model)\n",
    "        x = x_embd + x_pos                           # (batch_size, seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for layer in self.layers: \n",
    "            x, attention_weight = layer(x, enc_mask) \n",
    "       \n",
    "        return x, attention_weight\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_ff, n_head, drop_prob):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attention = MultiHeadAttention(d_model, n_head)\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.enc_dec_attention = MultiHeadAttention(d_model, n_head)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.feedforward = FeedForward(d_model, d_ff, drop_prob)\n",
    "        self.ln3 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "    def forward(self, dec_x, enc_out, dec_mask, enc_dec_mask):\n",
    "        # input \n",
    "        #       dec_x   (batch_size, dec_seq_len, d_model)\n",
    "        #       enc_out (batch_size, enc_seq_len, d_model)\n",
    "        # output\n",
    "        #       x                        (batch_size, dec_seq_len, d_model)\n",
    "        #       attention_weight_dec     (batch_size, n_head, dec_seq_len, dec_seq_len)\n",
    "        #       attention_weight_enc_dec (batch_size, n_head, dec_seq_len, enc_seq_len)\n",
    "        \n",
    "        residual, attention_weight_dec = self.self_attention(q=dec_x, k=dec_x, v=dec_x, mask=dec_mask) \n",
    "        residual = self.dropout(residual) \n",
    "        x = self.ln1(dec_x + residual)\n",
    "\n",
    "        residual, attention_weight_enc_dec = self.enc_dec_attention(q=x, k=enc_out, v=enc_out, mask=enc_dec_mask) \n",
    "        residual = self.dropout(residual) \n",
    "        x = self.ln2(x + residual)\n",
    "\n",
    "        residual = self.feedforward(x)\n",
    "        residual = self.dropout(residual)\n",
    "        x = self.ln3(x + residual)\n",
    "\n",
    "        return x, attention_weight_dec, attention_weight_enc_dec\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, d_model, d_ff, n_head, drop_prob, max_len, n_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, d_ff, n_head, drop_prob) for _ in range(n_layers)])\n",
    "        self.linear = nn.Linear(d_model, vocab_size) # for output\n",
    "\n",
    "    def forward(self, dec_x, enc_out, dec_mask, enc_dec_mask):\n",
    "        # input \n",
    "        #       dec_x   (batch_size, dec_seq_len, d_model)\n",
    "        #       enc_out (batch_size, enc_seq_len, d_model)\n",
    "        # output\n",
    "        #       x                        (batch_size, dec_seq_len, d_model)\n",
    "        #       attention_weight_dec     (batch_size, n_head, dec_seq_len, dec_seq_len)\n",
    "        #       attention_weight_enc_dec (batch_size, n_head, dec_seq_len, enc_seq_len)\n",
    "\n",
    "        \n",
    "        x_embd = self.embedding(dec_x).to(device)\n",
    "        x_pos = self.pos_encoding(dec_x).to(device)\n",
    "        x = x_embd + x_pos\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x, attention_weight_dec, attention_weight_enc_dec = layer(x, enc_out, dec_mask, enc_dec_mask)\n",
    "            \n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x, attention_weight_dec, attention_weight_enc_dec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdac6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, d_model, d_ff, n_head, drop_prob, max_len, n_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(vocab_size, d_model, d_ff, n_head, drop_prob, max_len, n_layers)\n",
    "        self.decoder = Decoder(vocab_size, d_model, d_ff, n_head, drop_prob, max_len, n_layers)\n",
    "        self.n_head = n_head\n",
    "\n",
    "        for m in self.modules():\n",
    "            if hasattr(m,'weight') and m.weight.dim() > 1: \n",
    "                nn.init.xavier_uniform_(m.weight)          \n",
    "\n",
    "    def forward(self, src, trg):\n",
    "\n",
    "        enc_pad_mask = self.make_enc_mask(src)\n",
    "        dec_mask = self.make_dec_mask(trg)\n",
    "        enc_dec_pad_mask = self.make_enc_dec_mask(src, trg)\n",
    "\n",
    "        enc_out, attention_weight_enc = self.encoder(src, enc_pad_mask)\n",
    "        out, attention_weight_dec, attention_weight_enc_dec = self.decoder(trg, enc_out, dec_mask, enc_dec_pad_mask)\n",
    "\n",
    "        return out, attention_weight_enc,  attention_weight_dec, attention_weight_enc_dec\n",
    "\n",
    "    def make_enc_mask(self, src):\n",
    "        # input\n",
    "        #      src(batch_size, enc_seq_len)\n",
    "        # output \n",
    "        #      enc_mask(batch_size, n_head, enc_seq_len, enc_seq_len)\n",
    "    \n",
    "        # encoder pad mask \n",
    "        batch_size, enc_seq_len = src.size()\n",
    "        enc_pad_mask = (src == pad_idx).unsqueeze(1).unsqueeze(2)           # (batch_size, 1, 1, enc_seq_len)\n",
    "        enc_pad_mask = enc_pad_mask.repeat(1, self.n_head, enc_seq_len, 1)  # (batch_size, n_head, enc_seq_len, enc_seq_len)\n",
    "        \"\"\" \n",
    "        src pad mask \n",
    "            나는 학생 이다 pad\n",
    "        나는  F   F   F  T\n",
    "        학생  F   F   F  T\n",
    "        이다  F   F   F  T\n",
    "        pad  F   F   F  T\n",
    "        \"\"\"\n",
    "        return enc_pad_mask\n",
    "\n",
    "    def make_dec_mask(self, trg):\n",
    "        # input\n",
    "        #      trg(batch_size, dec_seq_len)\n",
    "        # output \n",
    "        #      dec_mask(batch_size, n_head, dec_seq_len, dec_seq_len)\n",
    "        \n",
    "        # decoder pad mask \n",
    "        batch_size, dec_seq_len = trg.size()\n",
    "        dec_pad_mask = (trg == pad_idx).unsqueeze(1).unsqueeze(2)           # (batch_size, 1, 1, dec_seq_len)\n",
    "        dec_pad_mask = dec_pad_mask.repeat(1, self.n_head, dec_seq_len, 1)  # (batch_size, n_head, dec_seq_len, dec_seq_len)\n",
    "        \"\"\" \n",
    "        trg pad mask\n",
    "        F F F T T\n",
    "        F F F T T\n",
    "        F F F T T\n",
    "        F F F T T\n",
    "        F F F T T\n",
    "        \"\"\"\n",
    "        # decoder future mask \n",
    "        dec_future_mask = (torch.tril(torch.ones(batch_size, self.n_head, dec_seq_len, dec_seq_len)) == 0).to(device)\n",
    "        \"\"\"\n",
    "        trg future mask\n",
    "        F T T T T\n",
    "        F F T T T\n",
    "        F F F T T\n",
    "        F F F F T\n",
    "        F F F F F\n",
    "        \"\"\"\n",
    "        # decoder mask \n",
    "        dec_mask = dec_pad_mask | dec_future_mask\n",
    "        \"\"\" \n",
    "        dec_mask \n",
    "        F T T T T\n",
    "        F F T T T\n",
    "        F F F T T\n",
    "        F F F T T\n",
    "        F F F T T\n",
    "        \"\"\"\n",
    "        return dec_mask \n",
    "    \n",
    "    def make_enc_dec_mask(self, src, trg):\n",
    "        # input\n",
    "        #      src(batch_size, enc_seq_len)\n",
    "        #      trg(batch_size, dec_seq_len)\n",
    "        # output \n",
    "        #      enc_dec_mask(batch_size, n_head, dec_seq_len, enc_seq_len)\n",
    "    \n",
    "        # encoder-decoder pad mask(src의 pad 마스킹)\n",
    "        batch_size, dec_seq_len = trg.size()\n",
    "        enc_dec_pad_mask = (src == pad_idx).unsqueeze(1).unsqueeze(2)              # (batch_size, 1, 1, enc_seq_len)\n",
    "        enc_dec_pad_mask = enc_dec_pad_mask.repeat(1, self.n_head, dec_seq_len, 1) # (batch_size, n_head, dec_seq_len, enc_seq_len)\n",
    "        \n",
    "        return enc_dec_pad_mask\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf55021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005bec5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b92ca06",
   "metadata": {},
   "source": [
    "##### 데이터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb6a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data \n",
    "# https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=126\n",
    "\n",
    "data_path = '/Users/hyejinlee/Downloads/transformer_data/2_대화체.xlsx'\n",
    "data = pd.read_excel(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.loc[idx, '원문'], self.data.loc[idx, '번역문']\n",
    "\n",
    "DS = Dataset(data)\n",
    "train_DS, val_DS, test_DS, _ = torch.utils.data.random_split(DS, [5000, 1000, 1000, len(DS)-7000])\n",
    "\n",
    "BATCH_SIZE = 64  \n",
    "train_DL = torch.utils.data.DataLoader(train_DS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_DL = torch.utils.data.DataLoader(val_DS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_DL = torch.utils.data.DataLoader(test_DS, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f746684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "src, trg = train_DS[0]\n",
    "print(src)\n",
    "print(trg)\n",
    "\n",
    "for src_batch, trg_batch in train_DL:\n",
    "    print(len(src_batch))\n",
    "    print(len(trg_batch))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3634fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 \n",
    "tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-ko-en')\n",
    "eos_idx = tokenizer.eos_token_id\n",
    "pad_idx = tokenizer.pad_token_id\n",
    "\n",
    "print('tokenize')\n",
    "src_token = tokenizer.tokenize(src)\n",
    "trg_token = tokenizer.tokenize(trg)\n",
    "print(src_token)\n",
    "print(trg_token, '\\n')\n",
    "\n",
    "print('encode')\n",
    "src_encode = tokenizer.encode(src_token, add_special_tokens = False)\n",
    "trg_encode = tokenizer.encode(trg_token, add_special_tokens = False)\n",
    "print(src_encode)\n",
    "print(trg_encode, '\\n')\n",
    "\n",
    "print('decode')\n",
    "src_decode = tokenizer.decode(src_encode)\n",
    "trg_decode = tokenizer.decode(trg_encode)\n",
    "print(src_decode)\n",
    "print(trg_decode, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8762e0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff028b46",
   "metadata": {},
   "source": [
    "##### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pretrained embedding 로드 \n",
    "# MT_model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-ko-en') # MT: Machine Translation\n",
    "# pretrained_embeddings = MT_model.get_input_embeddings().weight         # (65001, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eb7212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter \n",
    "\n",
    "vocab_size = tokenizer.vocab_size\n",
    "num_epoch = 15\n",
    "max_len = 100\n",
    "n_layers = 3\n",
    "d_model = 256\n",
    "d_ff = 512\n",
    "n_head = 8\n",
    "drop_prob = 0.1\n",
    "\n",
    "# model \n",
    "model = Transformer(vocab_size, d_model, d_ff, n_head, drop_prob, max_len, n_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference 예시 \n",
    "\n",
    "src = torch.tensor([src_encode]).to(device)\n",
    "trg = torch.tensor([trg_encode]).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out, attention_weight_enc, attention_weight_dec, attention_weight_enc_dec = model(src, trg)\n",
    "    \n",
    "print(out.shape)\n",
    "print(out)\n",
    "\n",
    "print(attention_weight_enc.shape)\n",
    "print(attention_weight_dec.shape)\n",
    "print(attention_weight_enc_dec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e55f6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8430a4dc",
   "metadata": {},
   "source": [
    "##### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = pad_idx)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9, weight_decay=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d18ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamScheduler:\n",
    "    \n",
    "    def __init__(self, optimizer, d_model, warmup_steps, lr_scale):\n",
    "        self.optimizer = optimizer\n",
    "        self.current_step = 0\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.lr_scale = lr_scale\n",
    "\n",
    "    def step(self):\n",
    "        self.current_step += 1\n",
    "        lrate = self.lr_scale * (self.d_model ** -0.5) * min(self.current_step ** -0.5, self.current_step * self.warmup_steps ** -1.5)\n",
    "        self.optimizer.param_groups[0]['lr'] = lrate\n",
    "\n",
    "scheduler = NoamScheduler(optimizer, d_model, warmup_steps=1500, lr_scale=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3df519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, dataloder, tokenizer, max_len, criterion, optimizer, scheduler=None):\n",
    "    \n",
    "    N = len(dataloder.dataset)\n",
    "    total_loss = 0\n",
    "    \n",
    "    for src, trg in tqdm(dataloder):\n",
    "    \n",
    "        # 1) tokenizing src, trg\n",
    "        src = tokenizer(src, padding=True, truncation=True, max_length = max_len, return_tensors='pt').input_ids.to(device)\n",
    "        trg = ['</s> '+ trg_text for trg_text in trg]\n",
    "        trg = tokenizer(trg, padding=True, truncation=True, max_length = max_len, return_tensors='pt').input_ids.to(device)\n",
    "    \n",
    "        # 2) inference\n",
    "        y_hat = model(src, trg[:, :-1])[0] # (batch_size, max_len, d_model)\n",
    "    \n",
    "        # 3) loss\n",
    "        loss = criterion(y_hat.permute(0, 2, 1), trg[:, 1:]) # scalar \n",
    "    \n",
    "        # 4) update params \n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # scalar에 대해 backward \n",
    "            optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # 5) history \n",
    "        loss = loss.item() * src.shape[0]\n",
    "        total_loss += loss\n",
    "        \n",
    "    final_loss = total_loss / N\n",
    "    \n",
    "    return final_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_lst, val_loss_lst = list(), list()\n",
    "best_loss = 99999\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "\n",
    "    # train \n",
    "    model.train() \n",
    "    train_loss = calculate_loss(model, train_DL, tokenizer, max_len, criterion, optimizer, scheduler)\n",
    "    train_loss_lst.append(train_loss)\n",
    "\n",
    "    # validation \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = calculate_loss(model, val_DL, tokenizer, max_len, criterion, optimizer=None, scheduler=None)\n",
    "        val_loss_lst.append(val_loss)\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "    \n",
    "            # save \n",
    "            path = f'./result/model_{epoch+1}.pt'\n",
    "            state_dict = {'epoch':epoch+1, 'model':model, 'optimizer':optimizer}\n",
    "            torch.save(state_dict, path)\n",
    "   \n",
    "    # print loss\n",
    "    print(f\"Epoch {epoch+1}: train_loss: {train_loss:.5f} validation_loss: {val_loss:.5f}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c058d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "146229c5",
   "metadata": {},
   "source": [
    "#### 학습 모델로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./PapersWithCode/transformer_model.pt', map_location=device) # cpu\n",
    "# checkpoint = torch.load('./PapersWithCode/transformer_model.pt') # gpu\n",
    "\n",
    "model.load_state_dict(checkpoint['model'].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ad037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8344bbda",
   "metadata": {},
   "source": [
    "##### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f1147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation(model, tokenizer, src, max_len):\n",
    "    \n",
    "    src = tokenizer.encode(src, return_tensors='pt').to(device)\n",
    "    enc_mask = model.make_enc_mask(src)  # (batch_size, n_head, enc_seq_len, enc_seq_len)\n",
    "    enc_out, attention_weight_enc = model.encoder(src, enc_mask)\n",
    "\n",
    "    pred = tokenizer.encode('</s>', return_tensors='pt', add_special_tokens=False).to(device)\n",
    "    for _ in range(max_len):\n",
    "        dec_mask = model.make_dec_mask(pred)               # (batch_size, n_head, dec_seq_len, dec_seq_len)\n",
    "        enc_dec_mask = model.make_enc_dec_mask(src, pred)  # (batch_size, n_head, dec_seq_len, enc_seq_len)\n",
    "        \n",
    "        # out(batch_size, n_head, dec_seq_len, word_size)\n",
    "        out, attention_weight_dec, attention_weight_enc_dec = model.decoder(pred, enc_out, dec_mask, enc_dec_mask)\n",
    "        pred_word = out.argmax(dim=2)[:, -1].unsqueeze(0)  # (1,1)\n",
    "        pred = torch.cat([pred, pred_word], dim=1)         # (batch_size, dec_seq_len)\n",
    "\n",
    "        if tokenizer.decode(pred_word.item()) == '</s>':\n",
    "            break\n",
    "    translated_text = tokenizer.decode(pred[0])\n",
    "\n",
    "    return translated_text, attention_weight_enc, attention_weight_dec, attention_weight_enc_dec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a09930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for src, trg in test_DS:\n",
    "    break\n",
    "print(src)\n",
    "print(trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce7acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_text, attention_weight_enc, attention_weight_dec, attention_weight_enc_dec = translation(model, tokenizer, src, max_len)\n",
    "translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bba3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da1c9a26",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595beab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41884b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c3c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bee417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72bf77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75afe02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ea55d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7cd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1105c47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80856ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aeafbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1173db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba40884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebac449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae99479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
